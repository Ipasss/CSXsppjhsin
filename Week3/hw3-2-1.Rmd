---
title: "hw3-2 PTT WomenTalk"
author: "Pjhsin"
date: "2018/7/20"
output: html_document
---
#PTT WomenTalk 分析
https://www.ptt.cc/bbs/WomenTalk/index.html

1.Load needed packages
```{r}
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
```

2.PTT 網路爬蟲抓出所有文章內文所對應的網址
```{r}
from <- 7424 # 2018-07-20
to   <- 7434 # 2018-07-22
prefix = "https://www.ptt.cc/bbs/WomenTalk/index"

data <- list()
for( id in c(from:to) )
{
  url  <- paste0( prefix, as.character(id), ".html" )
  html <- htmlParse( GET(url) )
  url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
  data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)

head(data)
```

3.利用所有文章的網址去抓所有文章內文, 並解析出文章的內容並依照 hour 合併儲存。
```{r}
library(dplyr)
getdoc <- function(url)
{
    html <- htmlParse( getURL(url) )
    doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
    time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
    temp <- gsub( "  ", " 0", unlist(time) )
    part <- strsplit( temp, split=" ", fixed=T )
    #date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
    #date <- paste(part[[1]][2], part[[1]][5], sep="_")
    #date <- paste(part[[1]][1], part[[1]][2], sep="_")
    timestamp <- part[[1]][4]
    timestamp <- strsplit( timestamp, split=":", fixed=T )
    hour <- timestamp[[1]][1]
    #print(hour)
    name <- paste0('~/Documents/GitHub/CSXsp/Week3/DATA/', hour, ".txt")
    write(doc, name, append = TRUE)
}

sapply(data, getdoc)
```

4.建立文本資料結構與基本文字清洗
```{r}
library("tm")
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)

#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))})

d.corpus <- Corpus( DirSource("~/Documents/GitHub/CSXsp/Week3/DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
    gsub("[A-Za-z0-9]", "", word)
})
  
d.corpus <- tm_map(d.corpus, toSpace, "※")
d.corpus <- tm_map(d.corpus, toSpace, "◆")
d.corpus <- tm_map(d.corpus, toSpace, "‧")
d.corpus <- tm_map(d.corpus, toSpace, "的")
d.corpus <- tm_map(d.corpus, toSpace, "我")
d.corpus <- tm_map(d.corpus, toSpace, "是")
d.corpus <- tm_map(d.corpus, toSpace, "看板")
d.corpus <- tm_map(d.corpus, toSpace, "作者")
dd.corpus <- tm_map(d.corpus, toSpace, "發信站")
d.corpus <- tm_map(d.corpus, toSpace, "批踢踢實業坊")
d.corpus <- tm_map(d.corpus, toSpace, "阿")
d.corpus <- tm_map(d.corpus, toSpace, "啊")
d.corpus <- tm_map(d.corpus, toSpace, "欸")
d.corpus <- tm_map(d.corpus, toSpace, "了")
d.corpus <- tm_map(d.corpus, toSpace, "你")
d.corpus <- tm_map(d.corpus, toSpace, "文章")
d.corpus <- tm_map(d.corpus, toSpace, "網址")
d.corpus <- tm_map(d.corpus, toSpace, "標題")
d.corpus <- tm_map(d.corpus, toSpace, "發信站")
d.corpus <- tm_map(d.corpus, toSpace, "[a-zA-Z]")
d.corpus <- tm_map(d.corpus, stripWhitespace)
d.corpus
```

5.進行斷詞，並依照日期建立文本矩陣 TermDocumentMatrix
```{r}
mixseg = worker()
jieba_tokenizer = function(d)
{
  unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)

count_token = function(d)
{
  as.data.frame(table(d))
}
tokens = lapply(seg, count_token)

n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
  TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
  names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
library(knitr)
kable(head(TDM))
kable(tail(TDM))
```

6.將已建好的 TDM 轉成 TF-IDF
```{r}
tf <- apply(as.matrix(TDM[,2:(n+1)]), 2, sum)

library(Matrix)
idfCal <- function(word_doc)
{ 
  log2( n / nnzero(word_doc) ) 
}
idf <- apply(as.matrix(TDM[,2:(n+1)]), 1, idfCal)

doc.tfidf <- TDM
# for(x in 1:nrow(TDM))
# {
#   for(y in 2:ncol(TDM))
#   {
#     doc.tfidf[x,y] <- (doc.tfidf[x,y] / tf[y]) * idf[x]
#   }
# }

tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX

stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)

kable(head(doc.tfidf[delID,1]))
kable(tail(doc.tfidf[delID,1]))
TDM = TDM[-delID,]
doc.tfidf = doc.tfidf[-delID,]
```

7.TF-IDF Hours 文章取得的重要關鍵字
```{r}
TopWords = data.frame()
for( id in c(1:n) )
{
  dayMax = order(doc.tfidf[,id+1], decreasing = TRUE)
  showResult = t(as.data.frame(doc.tfidf[dayMax[1:5],1]))
  TopWords = rbind(TopWords, showResult)
}
rownames(TopWords) = colnames(doc.tfidf)[2:(n+1)]
TopWords = droplevels(TopWords)
kable(TopWords)
```

8.TF-IDF Hours 文章取得的重要關鍵字 TDM merge 視覺化
```{r}

TDM$d = as.character(TDM$d)
AllTop = as.data.frame( table(as.matrix(TopWords)) )
AllTop = AllTop[order(AllTop$Freq, decreasing = TRUE),]

kable(head(AllTop))

TopNo = 5
tempGraph = data.frame()
for( t in c(1:TopNo) )
{
  par(family="STKaiti")
  word = matrix( rep(c(as.matrix(AllTop$Var1[t])), each = n), nrow = n )
  temp = cbind( colnames(doc.tfidf)[2:(n+1)], t(TDM[which(TDM$d == AllTop$Var1[t]), 2:(n+1)]), word )
  colnames(temp) = c("hour", "freq", "words")
  tempGraph = rbind(tempGraph, temp)
  names(tempGraph) = c("hour", "freq", "words")
}

library(ggplot2)

library(varhandle)
par(family="STKaiti")
tempGraph$freq = unfactor(tempGraph$freq)
ggplot(tempGraph, aes(hour, freq), family = "STKaiti") + 
  geom_point(aes(color = words, shape = words), size = 5) +
  geom_line(aes(group = words, linetype = words)) 
```

註：中文字型使用par(family="STKaiti")依然跑不出來，先在此註解，words圖標由上而下對應到的字依序是：穿、打招呼、文組、學歷、中國。

```{r}
kable(tail(AllTop))
```

9.發文時間與發文量
```{r}
filenames = as.array(paste0("~/Documents/GitHub/CSXsp/Week3/DATA/",colnames(doc.tfidf)[2:(n+1)],".txt"))
sizeResult = apply(filenames, 1, file.size) / 1024
showSize = data.frame(colnames(doc.tfidf)[2:(n+1)], sizeResult)
names(showSize) = c("hour", "size_KB")

ggplot(showSize, aes(x = hour, y = size_KB)) + geom_bar(stat="identity")
```

##My Observation
1.PTT WomenTalk版發文的高峰時間為18:00，低峰為6:00。

2.探討“打招呼”一詞在此版討論度高的原因，主要源於：“[閒聊] 長輩到底多在乎晚輩打招呼？”這篇文章，不僅正文底下留言數量破百，並另有八篇文章為回覆此主題而開。而此篇正文是在13:18發布，短時間內即被熱烈討論，才會在13:00~14:00間爆量出現近125次的“打招呼”，可見此主題在女人聊天版共鳴度之高。
