---
title: "Women's Clothing E-Commerce Reviews"
author: "Pjhsin"
date: "2018/7/18"
output: html_document
---
#reference:
https://www.kaggle.com/dubravkodolic/reviews-of-clothings-analyzed-by-sentiments

#load packages
```{r}
library(readr)
library(magrittr)
library(tidyverse)
library(ineq)
library(cluster)
library(histogram)
library(ggplot2)
library(xyloplot)
library(tidytext)
library(COUNT)
library(data.table)
library(reshape2)
library(wordcloud)
```

##Read the data
```{r}
raw <- read_csv("Documents/GitHub/CSXsp/Week3/Womens Clothing E-Commerce Reviews.csv")
```
##Descriptive examination
###Top-ten Clothing ID
```{r}
raw %>%
  group_by(`Clothing ID`) %>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup() %>%
  mutate(clothid = reorder(`Clothing ID`,Count)) %>%
  head(10) %>%
  ggplot(aes(x = clothid, y = Count)) +
  geom_bar(stat='identity',colour="white", fill = "orange") +
  geom_text(aes(x = clothid, y = 1, label = paste0("(",Count,")",sep="")),
            hjust=0, vjust=.5, size = 4, colour = 'black',
            fontface = 'bold') +
  labs(x = 'ID of Cloth', 
       y = 'Count', 
       title = 'Clothing ID and Count') +
  coord_flip() +
  theme_bw()
```

###Are the ratings evenly distributed?: plot a Lorenz curve.
```{r}
x <- table(raw$`Clothing ID`)
lc.cloth <- Lc(x)
g.cloth <- ineq(x)
# create data.frame from LC
p <- lc.cloth[1]
L <- lc.cloth[2]
df <- data.frame(p,L)

# plot
ggplot(data = df) +
  geom_line(aes(x = p, y = L), color="red") +
  scale_x_continuous(name="Cumulative share of X", limits=c(0,1)) + 
  scale_y_continuous(name="Cumulative share of Y", limits=c(0,1)) +
  geom_abline() +
  labs(title = paste("Concentration of Clothings in data (Gini:", round(g.cloth, 2), ")"))
```

The Lorenz curve as well as the very high Gini coefficient (scaled between 0 and 1) suggest, that some very less clothings are overrepresented. This could lead to poor quality in possible modelings as there is not enough variety among the cloth.

###Some more descriptives on the top ten clothings
```{r}
top.ten <- as.data.frame(head(sort(table(raw$`Clothing ID`), decreasing = TRUE), 10))
d <- raw[raw$`Clothing ID` %in% top.ten$Var1,]

histogram(~Age|factor(`Clothing ID`), data = d, col = "orange", main = "Distribution of Age for top ten Clothings", xlab = "Age")
```

```{r}
bwplot(~Rating|factor(`Clothing ID`), data = d, col = "orange", 
       main  = "Ratings for top ten Clothings", xlab = "Rating")
```

The age seems to be evenly distributed amongst the top ten of clothings. With one exeption (Cloth ID 868) same holds true for the rataings. This is good as none of the over-represented cloths has a very specific (good or bad) rating.

###Ratings in dependency of other variables: Lattice graphs
```{r}
bwplot(factor(Rating) ~ Age|factor(`Division Name`) + factor(`Recommended IND`), 
       data = raw, xlab = "Age", main = "Age, Rating and Recommendation status")
```

```{r}
xyplot(factor(Rating) ~ Age|factor(`Division Name`), groups = factor(`Recommended IND`),
       data = raw)
```

```{r}
bwplot(Rating ~ factor(`Recommended IND`)|factor(`Division Name`),
       data = raw)
```

In the three divisions for cloths we find a quite similar distribution of the age on all five rating classes. In the first graoh we see the distribution of age grouped by ratings and classified by the recommendation status. A recommendation status of 1 means, that the customer recommends this item while a 0 stand for non-recommending this cloth. The second graoh shows with its colouring from red to blue that lower ratings are more likely to not being recommended.It seems that with growing age the rating and the recommendation behaviour gets more strict.

The last boxplot reveals the relation between ratings and recommendations very obviously. Ratings lower than a 3 tend to lead to a non-recommendation

##Sentiment analysis: analyzing reviews
```{r}
raw %>% 
  unnest_tokens(word, `Review Text`) %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>%
  head(10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  labs(x = NULL, title = "Most used words in Reviews") +
  coord_flip()
```

```{r}
library(dplyr)
raw %>% 
  unnest_tokens(word, `Review Text`) %>% 
  anti_join(stop_words) %>% 
  count(word, Rating, sort = TRUE) %>%
  dplyr::select(n, word, Rating) %>%
  group_by(Rating) %>% 
  top_n(n = 5, wt = n) %>% 
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
  facet_grid(. ~ Rating)
```

```{r}
by.rating.word <- as.data.table(raw %>% 
                                  unnest_tokens(word, `Review Text`) %>% 
                                  anti_join(stop_words) %>% 
                                  count(word, Rating, sort = TRUE))

by.pct.word <- by.rating.word[, gr.pct := n/sum(n), by = Rating]

by.rating.word %>% 
  group_by(Rating) %>% 
  top_n(n = 5, wt = gr.pct) %>% 
  ggplot(aes(word, (gr.pct*100))) +
  geom_col(aes(fill = (gr.pct*100))) +
  xlab(NULL) +
  ylab("Pct. per Rating") +
  theme(axis.text.x = element_text(angle=90, vjust=0.5)) +
  scale_fill_gradient(low = "lightblue", high = "darkblue", name = "Pct.") +
  coord_flip() +
  facet_grid(. ~ Rating)
```

###Wordclouds
```{r}
rate.cols <- c("#d7191c", "#fdae61", "#fc8d59", "#a6d96a", "#1a9641")
by.rating <- as.data.table(raw %>% 
                             unnest_tokens(bigram, `Review Text`, token = "ngrams", n = 2) %>% 
                             separate(bigram, c("word1", "word2"), sep = " ") %>% 
                             filter(!word1 %in% stop_words$word) %>%
                             filter(!word2 %in% stop_words$word) %>% 
                             unite(bigram.unite, word1, word2, sep = " ", remove = FALSE) %>% 
                             count(bigram.unite, Rating, sort = TRUE))

by.pct <- by.rating[, gr.pct := n/sum(n), by = Rating]

by.rating %>% 
  group_by(Rating) %>% 
  top_n(n = 40, wt = gr.pct) %>% 
  acast(bigram.unite ~ Rating, value.var = "gr.pct", fill = 0) %>%
  comparison.cloud(title.size = 1, random.order = TRUE,
                   colors = rate.cols)
```

```{r}
each.wordcloud <- by.rating %>% 
  group_by(Rating) %>% 
  top_n(n = 50, wt = gr.pct)

opar <- par()
par(mfrow = c(3,2), mar = c(rep(0.5, 4)))
for (cc in 1:5){
  each.wordcloud %>% 
    filter(Rating == cc) %>% 
    with(wordcloud(bigram.unite, n, scale = c(5,0.2), colors = rate.cols[cc]))
  title(paste("Rating:", cc), cex = 0.5, col = rate.cols[cc])
}
par(opar)
```

##學習筆記
主要的障礙在install&load packages，因原文並未詳細描述這個部分。

要自己找出哪些function需要哪個package另；外要注意，某些packages還會互相干擾，需另做處理。